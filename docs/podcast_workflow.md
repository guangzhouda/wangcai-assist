# 播客配音工作流（建议）

实时语音助手追求“低延迟”；播客追求“自然度 + 情绪/语气 + 稳定音色 + 可后期”。建议把它当成 **离线批处理** 来做。

---

## 1) 你要先选：用 CosyVoice 还是 OpenVoice？

结论（实用主义）：

- **想要更自然 + 更可控的语气/情绪**：优先用 **CosyVoice** 来“生成语音本体”。
- **想固定成某个特定音色（你自己的声线/角色声线）**：用 **OpenVoice** 做“转音色”。
- **同时要“情绪 + 固定音色”**：推荐组合链路：

  1) 先用 CosyVoice 生成带情绪的底座语音（语速/停顿/笑声等更自然）
  2) 再用 OpenVoice 把底座语音“转成目标音色”

原因：OpenVoice 本质是音色转换，情绪/停顿/韵律更多来自“源音频”，它不会凭空把平淡句子变得很有感情。

---

## 2) 情绪怎么做？

### 方案 A：用 CosyVoice 的 Instruct（推荐）

CosyVoice 有专门的 “Instruct” 模型变体，用自然语言指令做风格控制（例如：温柔、兴奋、悲伤、播音腔、讲故事、强调某些词等）。

### 方案 B：准备多段参考音频（Prompt）做“情绪模板”

如果你用的是 zero-shot 固定音色方式（参考音频 + 参考文本）：

- 录 3~10 秒 **中性**、**开心**、**悲伤**、**神秘** 四种小样
- 同一个人同一设备录，尽量干净
- 合成不同段落时选择对应的 prompt

这样“情绪”会更稳定，也更像真实人声在换状态。

### 方案 C：在文本里显式写出播报动作（适合 LLM 生成脚本）

例如让 LLM 生成：

- （小声）…（停顿）…
- （笑）…
- （认真）…

然后你在 TTS 侧决定：

- 这些标记是直接朗读（不推荐）
- 还是被当作“控制指令/标签”（推荐：让模型理解它是风格提示）

---

## 3) 播客的工程化流水线

建议拆成 5 个阶段：

1) 脚本生成（LLM）
   - 输出结构化脚本：分段、角色、情绪、台词
   - 例：JSON/YAML：`speaker / mood / text`
2) 文本清洗
   - 统一数字读法（阿拉伯数字 -> 中文数字）
   - 去掉 markdown、链接、奇怪符号
3) 分段合成（TTS）
   - 按句/按段生成多个 wav，便于重做局部
4) 后期（推荐用 ffmpeg / Audition / Reaper）
   - 音量归一化（LUFS）
   - 轻度压缩/限幅（更像电台）
   - 去噪、去爆破音（可选）
   - 加 BGM、音效、片头片尾
5) 导出与发布
   - 输出 mp3/m4a
   - 生成章节/封面/简介

---

## 4) 本项目里要注意的点

- 你现在默认 TTS 是 `melo`（更适合“实时助手”）
- 做播客更建议切到：
  - `TTS_ENGINE=cosyvoice`（追求自然）
  - 或 `TTS_ENGINE=openvoice`（追求固定音色；底座用 melo）
- 如果你要让 TTS 保留类似 `<laughter>` 这类标签，记得关闭过滤：
  - `TTS_STRIP_NON_TEXT=0`

